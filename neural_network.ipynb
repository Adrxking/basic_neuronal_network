{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Implementación de la red neuronal con retropropagación\n",
    "\n",
    "class NetNode(object):\n",
    "\n",
    "  def __init__(self):\n",
    "    self.inputs = []\n",
    "    self.weights = []\n",
    "    self.value = None\n",
    "\n",
    "class Network(object):\n",
    "\n",
    "  def __init__(self, layers, activation='relu', regression=False):\n",
    "    self.net = [[NetNode() for _ in range(size)] for size in layers]\n",
    "    sizes = len(layers)\n",
    "    for layer in range(1, sizes):\n",
    "        for node in self.net[layer]:\n",
    "            for unit in self.net[layer - 1]:\n",
    "                node.inputs.append(unit)\n",
    "                node.weights.append(0)\n",
    "            node.weights = [np.random.uniform() for _ in range(len(node.weights))]\n",
    "    self.regression = regression\n",
    "    if activation == 'relu':\n",
    "        self.activation_func = self.relu\n",
    "        self.activation_func_prime = self.relu_prime\n",
    "    else:\n",
    "        self.activation_func = self.sigmoide\n",
    "        self.activation_func_prime = self.sigmoide_prime\n",
    "\n",
    "  def accuracy(self, examples):\n",
    "    correct = 0\n",
    "    error = 0\n",
    "    total = 0\n",
    "    for x_test, y_test in examples:\n",
    "      prediction = self.predict(x_test)\n",
    "      if self.regression:\n",
    "        index = 0\n",
    "        for value in prediction:\n",
    "          error += (y_test[index] - value) ** 2\n",
    "          index += 1\n",
    "          total += 1\n",
    "      else:\n",
    "        if (y_test[prediction] == 1):\n",
    "          correct += 1\n",
    "    if self.regression:\n",
    "      return 1 - error / total\n",
    "    else:\n",
    "      return correct / len(examples)\n",
    "\n",
    "  def backpropagation(self, eta, examples, epochs):\n",
    "    inputs = self.net[0]\n",
    "    outputs = self.net[-1]\n",
    "    layer_size = len(self.net)\n",
    "    for epoch in range(epochs):\n",
    "        for x_train, y_train in examples:\n",
    "            for value, node in zip(x_train, inputs):\n",
    "                node.value = value\n",
    "            for layer in self.net[1:]:\n",
    "                for node in layer:\n",
    "                    in_val = [n.value for n in node.inputs]\n",
    "                    unit_value = np.dot(in_val, node.weights)\n",
    "                    node.value = self.activation_func(unit_value)\n",
    "            delta = [[] for _ in range(layer_size)]\n",
    "            err = [y_train[i] - outputs[i].value for i in range(len(outputs))]\n",
    "            delta[-1] = [self.activation_func_prime(outputs[i].value) * err[i] for i in range(len(outputs))]\n",
    "            hidden_layers = layer_size - 2\n",
    "            for i in range(hidden_layers, 0, -1):\n",
    "                layer = self.net[i]\n",
    "                n_layers = len(layer)\n",
    "                w = [[node.weights[l] for node in self.net[i + 1]] for l in range(n_layers)]\n",
    "                delta[i] = [self.activation_func_prime(layer[j].value) * np.dot(w[j], delta[i + 1]) for j in range(n_layers)]\n",
    "            for i in range(1, layer_size):\n",
    "                layer = self.net[i]\n",
    "                in_val = [node.value for node in self.net[i - 1]]\n",
    "                n_layers = len(self.net[i])\n",
    "                for j in range(n_layers):\n",
    "                    layer[j].weights = np.add(layer[j].weights, np.multiply(eta * delta[i][j], in_val))\n",
    "        print(f\"epoch {epoch}/{epochs} | total error={np.sum(err)/len(examples)}\")\n",
    "    nodes = []\n",
    "    for layer in self.net[1:]:\n",
    "      for node in layer:\n",
    "        nodes.append(node.value)\n",
    "    return nodes\n",
    "  \n",
    "  def predict(self, input_data):\n",
    "    inputs = self.net[0]\n",
    "    for v, n in zip(input_data, inputs):\n",
    "        n.value = v\n",
    "    for layer in self.net[1:]:\n",
    "        for node in layer:\n",
    "            in_val = [n.value for n in node.inputs]\n",
    "            unit_value = np.dot(in_val, node.weights)\n",
    "            node.value = self.activation_func(unit_value)\n",
    "    if self.regression:\n",
    "      outputs = []\n",
    "      for node in self.net[-1]:\n",
    "        outputs.append(node.value)\n",
    "      return outputs\n",
    "    else:\n",
    "      outputs = self.net[-1]\n",
    "      return outputs.index(max(outputs, key=lambda node: node.value))\n",
    "\n",
    "  def relu(self, z):\n",
    "    print(z)\n",
    "    return max(0, z)\n",
    "\n",
    "  def relu_prime(self, z):\n",
    "    return 1 if z > 0 else 0\n",
    "\n",
    "  def sigmoide(self, z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "  def sigmoide_prime(self, z):\n",
    "    s = self.sigmoide(z)\n",
    "    return s * (1 - s)\n",
    "  \n",
    "  def set_weights(self, weights_list):\n",
    "    idx = 0\n",
    "    for layer in self.net[1:]:\n",
    "        for node in layer:\n",
    "          if len(node.weights) == len(weights_list[idx]):\n",
    "            node.weights = weights_list[idx]\n",
    "          idx += 1\n",
    "\n",
    "  def weights(self):\n",
    "    all_weights = []\n",
    "    for layer in self.net[1:]:\n",
    "        for node in layer:\n",
    "            all_weights.append(node.weights)\n",
    "    return all_weights\n",
    "\n",
    "# Usando la red neuronal con un dataset\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "\n",
    "iris_X, iris_y = datasets.load_iris(return_X_y=True)\n",
    "\n",
    "iris_x_normalized = normalize(iris_X, axis=0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_x_normalized, iris_y, test_size=0.2, shuffle=True)\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, num_classes=3)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes=3)\n",
    "\n",
    "examples = []\n",
    "for i in range(len(X_train)):\n",
    "    examples.append([X_train[i], y_train[i]])\n",
    "\n",
    "net = Network([4, 7, 3], regression=True)\n",
    "net.backpropagation(0.1, examples, 500)\n",
    "\n",
    "#precisión alcanzada con los datos de entrenamiento\n",
    "accuracy = net.accuracy(examples)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "#precisión alcanzada con los datos de prueba\n",
    "examples = []\n",
    "for i in range(len(X_test)):\n",
    "    examples.append([X_test[i], y_test[i]])\n",
    "accuracy = net.accuracy(examples)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "#probando con un dato\n",
    "prediction = net.predict(X_test[2])\n",
    "print(f\"Desired output: {y_test[2]}\")\n",
    "print(f\"Index of output: {prediction}\")\n",
    "\n",
    "# Modificación de la implementación de la red neuronal\n",
    "\n",
    "# agrega el método weigths() a la clase Network, de tal forma que permita obtener los pesos de las neuronas\n",
    "# agrega el método set_weights() a la clase Network, de tal forma que permite definir los pesos de las neuronas\n",
    "\n",
    "# agrega los métodos sigmoide() y sigmoide_prime() a la clase Network\n",
    "# modifica la clase Network, para que se pueda decidir qué función de activación utilizar: relu() o sigmoide()\n",
    "\n",
    "# los métodos predict() y accuracy() de la clase Network están implementados para resolver problemas de clasificación\n",
    "# modifícalos de tal manera que también se puedan utilizar con problemas de regresión\n",
    "\n",
    "# modifica el método backpropagation() de tal manera que devuelva como resultado el array de valores de los nodos durante las épocas de entrenamiento\n",
    "\n",
    "# una vez implementados los cambios, entrena la red neuronal del ejemplo de los apuntes\n",
    "examples = []\n",
    "examples.append([[0.5, 0.67, 0.5], [0.25, 0.6]])\n",
    "\n",
    "# ejecuta la red neuronal para los datos de ejemplo de los apuntes\n",
    "# comprueba los valores de los nodos y de los pesos\n",
    "# los valores de los nodos tienen que ser los mismos que los de los apuntes\n",
    "# los valores de los pesos son ligeramente diferentes, ¿por qué?\n",
    "\n",
    "net = Network([3, 4, 2])\n",
    "\n",
    "\n",
    "# net.set_weights([[0.1, 0.1, 0.1], [0.2, 0.2, 0.2], [0.3, 0.3, 0.3], [0.4, 0.4, 0.4], [0.5, 0.5, 0.5, 0.5], [0.6, 0.6, 0.6, 0.6], [0.6, 0.6, 0.6, 0.6]])\n",
    "# net.set_weights([[0.1, 0.1, 0.1], [0.2, 0.2, 0.2], [0.3, 0.3, 0.3], [0.4, 0.4, 0.4], [0.5, 0.5, 0.5, 0.5], [0.6, 0.6, 0.6, 0.6]])\n",
    "net.set_weights([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n",
    "print(net.weights())\n",
    "\n",
    "\n",
    "valores_nodos = net.backpropagation(0.9, examples, 1)\n",
    "\n",
    "print(valores_nodos)\n",
    "print(net.weights())\n",
    "\n",
    "import graphviz\n",
    "\n",
    "def draw_graph(net):\n",
    "    dot = graphviz.Digraph()\n",
    "    dot.attr('node', shape='circle')\n",
    "    for i, layer in enumerate(net.net):\n",
    "        with dot.subgraph(name=f'cluster_{i}') as c:\n",
    "            c.attr(style='invis')\n",
    "            for j, node in enumerate(layer):\n",
    "                c.node(f'{i},{j}')\n",
    "    for i, layer in enumerate(net.net):\n",
    "        for j, node in enumerate(layer):\n",
    "            for input_node, weight in zip(node.inputs, node.weights):\n",
    "                dot.edge(f'{i-1},{net.net[i-1].index(input_node)}', f'{i},{j}', label=f'{weight:.2f}')\n",
    "    return dot\n",
    "\n",
    "net2 = Network([3, 4, 2], 'sigmoide', True)\n",
    "\n",
    "net2.set_weights([[0.1, 0.1, 0.1], [0.2, 0.2, 0.2], [0.3, 0.3, 0.3], [0.4, 0.4, 0.4], [0.5, 0.5, 0.5, 0.5], [0.6, 0.6, 0.6, 0.6]])\n",
    "\n",
    "net2.weights()\n",
    "\n",
    "draw_graph(net2)\n",
    "\n",
    "examples = []\n",
    "examples.append([[0.5, 0.67, 0.5], [0.25, 0.6]])\n",
    "\n",
    "valores_nodos = net2.backpropagation(0.9, examples, 6000)\n",
    "\n",
    "valores_nodos\n",
    "\n",
    "net2.weights()\n",
    "\n",
    "net2.predict(examples[0][0])\n",
    "\n",
    "examples[0][1]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
